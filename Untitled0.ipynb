{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gribanov-Danil/ProjectWork2022.2-ndSemestr/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Импортируем необходимые модули*"
      ],
      "metadata": {
        "id": "-CXN65gEkAwf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "5bVWJRG2Il_V"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import shutil\n",
        "import os\n",
        "import tensorflow\n",
        "import numpy as np\n",
        "import cv2\n",
        "from keras.preprocessing import image\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.python.keras.models import Sequential\n",
        "from tensorflow.python.keras.layers import Conv2D, MaxPooling2D\n",
        "from tensorflow.python.keras.layers import Activation, Dropout, Flatten, Dense"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Настройка окружения*"
      ],
      "metadata": {
        "id": "tJyBsF_OkgAi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Каталог с данными для обучения\n",
        "train_dir = r'test/'\n",
        "# Каталог с данными для проверки\n",
        "val_dir = r'test/'\n",
        "# Каталог с данными для тестирования\n",
        "test_dir = r'test/'\n",
        "train1 = r'test/Steel/Steel.1'\n",
        "# Размеры изображения\n",
        "img_width, img_height = 150, 150\n",
        "# Размерность тензора на основе изображения для входных данных в нейронную сеть\n",
        "# backend Tensorflow, channels_last\n",
        "input_shape = (img_width, img_height, 3)\n",
        "# Количество эпох\n",
        "epochs = 10\n",
        "# Размер мини-выборки\n",
        "batch_size = 1\n",
        "# Количество изображений для обучения\n",
        "nb_train_samples = 9\n",
        "# Количество изображений для проверки\n",
        "nb_validation_samples = 9\n",
        "# Количество изображений для тестирования\n",
        "nb_test_samples = 9"
      ],
      "metadata": {
        "id": "Vq9CiqNxkQ_W"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Настраиваем модель*"
      ],
      "metadata": {
        "id": "dKqiZVZSkmM3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(32, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(3))\n",
        "model.add(Activation('sigmoid'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['categorical_accuracy'])"
      ],
      "metadata": {
        "id": "vZZPGluNkqo9"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "аугментация и прогонка по слоям"
      ],
      "metadata": {
        "id": "JXGKr7wIk2oK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical')\n",
        "\n",
        "val_generator = datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical')\n",
        "\n",
        "test_generator = datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical')\n",
        "\n",
        "model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=nb_train_samples // batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_data=val_generator,\n",
        "    validation_steps=nb_validation_samples // batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gnnHL1Cgk60G",
        "outputId": "617ca7c3-d9f5-4549-ef67-010ccd6a0bc7"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 9 images belonging to 3 classes.\n",
            "Found 9 images belonging to 3 classes.\n",
            "Found 9 images belonging to 3 classes.\n",
            "Epoch 1/10\n",
            "9/9 [==============================] - 4s 249ms/step - loss: 1.1993 - categorical_accuracy: 0.3333 - val_loss: 1.1374 - val_categorical_accuracy: 0.6667\n",
            "Epoch 2/10\n",
            "9/9 [==============================] - 1s 147ms/step - loss: 1.1734 - categorical_accuracy: 0.5556 - val_loss: 0.9945 - val_categorical_accuracy: 0.5556\n",
            "Epoch 3/10\n",
            "9/9 [==============================] - 1s 165ms/step - loss: 1.2666 - categorical_accuracy: 0.2222 - val_loss: 0.9771 - val_categorical_accuracy: 0.8889\n",
            "Epoch 4/10\n",
            "9/9 [==============================] - 1s 141ms/step - loss: 0.9996 - categorical_accuracy: 0.4444 - val_loss: 0.9649 - val_categorical_accuracy: 0.5556\n",
            "Epoch 5/10\n",
            "9/9 [==============================] - 1s 124ms/step - loss: 0.8939 - categorical_accuracy: 0.7778 - val_loss: 0.7132 - val_categorical_accuracy: 0.8889\n",
            "Epoch 6/10\n",
            "9/9 [==============================] - 1s 137ms/step - loss: 0.7879 - categorical_accuracy: 0.5556 - val_loss: 0.3496 - val_categorical_accuracy: 1.0000\n",
            "Epoch 7/10\n",
            "9/9 [==============================] - 1s 122ms/step - loss: 0.3875 - categorical_accuracy: 1.0000 - val_loss: 0.2266 - val_categorical_accuracy: 1.0000\n",
            "Epoch 8/10\n",
            "9/9 [==============================] - 1s 125ms/step - loss: 1.2501 - categorical_accuracy: 0.6667 - val_loss: 0.1893 - val_categorical_accuracy: 1.0000\n",
            "Epoch 9/10\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.3021 - categorical_accuracy: 1.0000 - val_loss: 0.2544 - val_categorical_accuracy: 1.0000\n",
            "Epoch 10/10\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.3086 - categorical_accuracy: 0.8889 - val_loss: 0.0289 - val_categorical_accuracy: 1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f770efeb250>"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Вывод данных*"
      ],
      "metadata": {
        "id": "dNv-bq4Qk8nN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scores = model.evaluate_generator(test_generator, nb_test_samples // batch_size)\n",
        "print(\"Аккуратность на тестовых данных: %.2f%%\" % (scores[1]*100))\n",
        "\n",
        "def load_image(img_path, show=False):\n",
        "\n",
        "    img = image.load_img(img_path, target_size=(150, 150))\n",
        "    img_tensor = image.img_to_array(img)                    # (height, width, channels)\n",
        "    img_tensor = np.expand_dims(img_tensor, axis=0)         # (1, height, width, channels), add a dimension because the model expects this shape: (batch_size, height, width, channels)\n",
        "    img_tensor /= 255.                                      # imshow expects values in the range [0, 1]\n",
        "\n",
        "    return img_tensor\n",
        "\n",
        "new_image = load_image(r'test/Steel/Steel.1.jpg')\n",
        "pred = model.predict(new_image)\n",
        "print(pred)\n",
        "\n",
        "# img = cv2.imread(r'test/Steel/Steel.1.jpg')\n",
        "# img = cv2.resize(img,(img_width, img_height))\n",
        "# img = np.reshape(img,[1,img_width, img_height,3])\n",
        "# classes = model.predict_classes(img)\n",
        "\n",
        "# print(classes)\n",
        "\n",
        "\n",
        "# use_samples = [0, 1]\n",
        "# samples_to_predict = []\n",
        "\n",
        "# #for sample in use_samples:\n",
        "#   #samples_to_predict.append(train1[sample])\n",
        "# use_samples = [5, 38, 3939, 27389]\n",
        "# samples_to_predict = []\n",
        "\n",
        "# # Generate plots for samples\n",
        "# for sample in use_samples:\n",
        "#   # Generate a plot\n",
        "\n",
        "#   # Add sample to array for prediction\n",
        "#   samples_to_predict.append(train1[sample])\n",
        "\n",
        "# # Convert into Numpy array\n",
        "\n",
        "\n",
        "# samples_to_predict = np.array(samples_to_predict)\n",
        "# predictions = model.predict(samples_to_predict)\n",
        "# print(predictions)\n",
        "# model_json = model.to_json()\n",
        "# json_file = open(\"mnist_model.json\", \"w\")\n",
        "# json_file.write(model_json)\n",
        "# json_file.close()\n",
        "\n",
        "# model.save_weights(\"mnist_model.h5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HggzZBqXk_V7",
        "outputId": "b3cc92ea-c6eb-429b-99d6-0259870f73f2"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1996: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n",
            "  warnings.warn('`Model.evaluate_generator` is deprecated and '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Аккуратность на тестовых данных: 100.00%\n",
            "[[0.22921094 0.20582068 0.7305859 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Or8Ly79Gae87",
        "outputId": "c4c619a5-5042-49b9-f32d-7034e8a05889",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    }
  ]
}